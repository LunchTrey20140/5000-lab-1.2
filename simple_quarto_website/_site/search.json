[
  {
    "objectID": "slides/slides.html#bayes",
    "href": "slides/slides.html#bayes",
    "title": "Bayesian Stuff",
    "section": "Bayes",
    "text": "Bayes\n\nThe man\nDefinitely an interesting history reading “Everything is Predictable” by Tom Chivey"
  },
  {
    "objectID": "slides/slides.html#bayesian-optimization",
    "href": "slides/slides.html#bayesian-optimization",
    "title": "Bayesian Stuff",
    "section": "Bayesian Optimization",
    "text": "Bayesian Optimization\nShahriari et al. (2016) talks a lot about this - We’ll get to some pets that approve of Bayesian optimization in a minute.\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndf = sns.load_dataset(\"penguins\")\n\n# Set theme\nsns.set_theme(style = 'white', palette = \"Pastel1\")\n\n# Assign an object to the .relplot command (based on the plot, it's a side by side scatterplot categorized by island across the plots and species within them)\ng = sns.relplot(\n    data = df,\n    x = \"bill_length_mm\",\n    y = \"flipper_length_mm\",\n    hue = \"species\",\n    col = \"island\",\n    s = 200)\n\n# Print Types\nprint('-----TYPES-----')\nprint(type(g.fig))\nprint(type(g.axes[0,0]))\nprint(type(g.axes[0,1]))\n\n# Font Size\nFS = 18\n\n# Axis Titles \ng.axes[0,0].set_xlabel('Penguin bill length (mm)', fontsize=FS)\ng.axes[0,1].set_xlabel('Penguin bill length (mm)', fontsize=FS)\ng.axes[0,2].set_xlabel('Penguin bill length (mm)', fontsize=FS)\ng.axes[0,0].set_ylabel('Penguin flipper length (mm)', fontsize=FS)\n\n# Axis Tic Font Size\nfor i in range(0,2):\n    g.axes[0,i].tick_params(axis='both', which='major', labelsize=FS)\n\n# Titles of each island's scatterplot\ng.axes[0,0].set_title(\"Torgersen Island\",fontsize=FS)\ng.axes[0,1].set_title(\"Biscoe Island\",fontsize=FS)\ng.axes[0,2].set_title(\"Dream Island\", fontsize=FS)\n\n# Modify the Legend\nplt.setp(g._legend.get_texts(), fontsize=FS)\nplt.setp(g._legend.get_title(), fontsize=FS)\n\n\n-----TYPES-----\n&lt;class 'matplotlib.figure.Figure'&gt;\n&lt;class 'matplotlib.axes._axes.Axes'&gt;\n&lt;class 'matplotlib.axes._axes.Axes'&gt;"
  },
  {
    "objectID": "slides/slides.html#bayesian-dogs",
    "href": "slides/slides.html#bayesian-dogs",
    "title": "Bayesian Stuff",
    "section": "Bayesian Dogs",
    "text": "Bayesian Dogs\n\nOdin and Nesa are for sure Bayesian Dogs\n\nI mean, Odin is shaped like Bread and that starts with a ‘B’ so shrug ;)  \n\n\n\n\n\n\n\n\n\n\nShahriari, Bobak, Kevin Swersky, Ziyu Wang, Ryan P. Adams, and Nando de Freitas. 2016. “Taking the Human Out of the Loop: A Review of Bayesian Optimization.” Proceedings of the IEEE 104 (1): 148–75. https://doi.org/10.1109/jproc.2015.2494218."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "simple_quarto_website",
    "section": "",
    "text": "Schoot et al. (2021) says a ton about one of my favorite topics: Bayesian Modeling Lorem ipsum odor amet, consectetuer adipiscing elit. Hendrerit elementum metus orci nisl; duis ultrices tellus. Himenaeos donec lectus natoque dolor cursus a aliquam.1 Imperdiet tortor nunc; integer rutrum purus metus. Potenti morbi hac ullamcorper integer lacus blandit commodo. Scelerisque elit semper malesuada sit leo nam. Class convallis class neque netus hendrerit accumsan vivamus imperdiet. Schoot et al. (2021)\n\n\nPurus suscipit sagittis senectus est etiam integer. Turpis nam morbi sodales mus laoreet duis. Sagittis malesuada himenaeos ex, hendrerit placerat class. Mi maecenas inceptos eget libero potenti;\n\nLorem ipsum odor amet, consectetuer adipiscing elit. Elementum potenti velit maecenas venenatis; placerat senectus. Ad sodales scelerisque curabitur sapien felis. Semper quam libero ultricies dignissim mus justo lectus. Himenaeos diam senectus tempor nisi elementum consequat sapien tellus. Nunc dapibus lacinia diam sem dignissim nisi mus porta porta. Eleifend blandit turpis habitant donec eleifend.\n\nbibendum taciti rutrum neque accumsan hendrerit montes consequat. Afringilla scelerisque senectus dis orci natoque phasellus. Fames pharetra nascetur dis imperdiet mollis fringilla. Donec faucibus vel adipiscing nullam gravida integer parturient:\n\nLitora ipsum lobortis tincidunt bibendum eget sed lacinia porta. Velit mollis vivamus sagittis quam mattis tempor diam, nulla nascetur. Luctus litora senectus senectus mus sem; vitae porttitor. Quis\nparturient nam finibus id. Quisque porta dictum metus; felis habitant pellentesque.\nVehicula consectetur gravida quam nulla dictum pretium natoque.\n\nHere’s a mermaid flow chart:\n\n\n\n\n\nflowchart LR\n  A[Get Up] --&gt; B(Brush Teeth)\n  B --&gt; C{Decision}\n  C --&gt; D[Make Breakfast]\n  C --&gt; E[Make Bed]\n\n\n\n\n\n\n\n\nTaciti tristique nibh primis pharetra pulvinar. Aliquet odio faucibus litora magna morbi mi lectus bibendum. Magna integer malesuada massa, commodo facilisis vulputate?\n\n\n\n\n\n\nLibero curae nisl nisl diam nisi consequat. Fames aliquam habitant potenti convallis vulputate phasellus elementum? Porta parturient sociosqu; nullam sit hac placerat porta arcu vehicula. Gravida nisi ultrices sed massa fringilla magnis efficitur aenean.\n\n\nLibero curae nisl nisl diam nisi consequat. Fames aliquam habitant potenti convallis vulputate phasellus elementum? Porta parturient sociosqu; nullam sit hac placerat porta arcu vehicula. Gravida nisi ultrices sed massa fringilla magnis efficitur aenean.\n\n\n\nThis is from my Undergraduate thesis:\n\n“If we let \\(\\theta_c^{(s)}\\) be the MCMC sample from iteration s of chain c for parameter \\(\\theta\\), and \\(\\theta_c^{(s-\\ell)}\\) be the MCMC sample from iteration \\(s-\\ell\\) of chain c for parameter \\(\\theta\\), then we can achieve our effective sample size and autocorrelation from our total number of iterations S by Equation:”\n\n\\[\n    Ess_c = \\frac{N}{1 + 2\\sum_{\\ell-1}^N\\rho_c(\\ell)} \\newline\n\\] \\[\n\\rho_c(\\ell) = Cor(\\theta_c^{(s)},\\theta_c^{(s-\\ell)})\n\\]\nwhere \\(\\ell\\) is the lag of our sample\nTo estimate the significance and uncertainty of my Köppen-Geiger Climate Classification coefficients, I calculated 95% Highest Posterior Density (HPD) Intervals for all model parameters, as seen in the table below. These HPD intervals are the credible intervals (\\(\\ell\\), u) such that the width \\(u - \\ell\\) is minimized while keeping the desired coverage probability such that P(\\(\\ell\\) &lt; \\(\\theta\\) &lt; u) = .95, but the width of the interval is as small as possible.\n\n\n\n\nTerm\nLower_Bound\nHigher_Bound\n\n\n\n\n1\n(Intercept)\n13.69\n13.86\n\n\n2\nXC2\n0.87\n0.87\n\n\n3\nCRegionBSk\n-2.08\n-1.91\n\n\n4\nCRegionBWh\n0.16\n0.37\n\n\n5\nCRegionBWk\n-0.32\n-0.12\n\n\n6\nCRegionCfa\n-1.90\n-1.73\n\n\n7\nCRegionCfb\n-1.62\n-1.38\n\n\n8\nCRegionCsa\n-1.48\n-1.28\n\n\n9\nCRegionCsb\n-1.87\n-1.70\n\n\n10\nCRegionDfa\n-3.70\n-3.52\n\n\n11\nCRegionDfb\n-2.60\n-2.42\n\n\n12\nCRegionDfc\n-1.74\n-1.54\n\n\n13\nCRegionDsb\n-1.56\n-1.34\n\n\n14\nCRegionDsc\n-0.85\n-0.57\n\n\n15\nCRegionDwa\n-3.50\n-3.15\n\n\n16\nCRegionDwb\n-3.41\n-2.94\n\n\n17\nsigma\n2.99\n3.01\n\n\n18\nmean_PPD\n11.85\n11.87\n\n\n\nHere are some images\n\n\n\nOne picture of Odin, my older sister’s dog\n\n\n\n\n\nThis dog is basically mine, I raised this chonky boy\n\n\nHere’s a video from my presentation in Germany"
  },
  {
    "objectID": "index.html#personal-stuff-a-little-about-me",
    "href": "index.html#personal-stuff-a-little-about-me",
    "title": "simple_quarto_website",
    "section": "",
    "text": "Purus suscipit sagittis senectus est etiam integer. Turpis nam morbi sodales mus laoreet duis. Sagittis malesuada himenaeos ex, hendrerit placerat class. Mi maecenas inceptos eget libero potenti;\n\nLorem ipsum odor amet, consectetuer adipiscing elit. Elementum potenti velit maecenas venenatis; placerat senectus. Ad sodales scelerisque curabitur sapien felis. Semper quam libero ultricies dignissim mus justo lectus. Himenaeos diam senectus tempor nisi elementum consequat sapien tellus. Nunc dapibus lacinia diam sem dignissim nisi mus porta porta. Eleifend blandit turpis habitant donec eleifend.\n\nbibendum taciti rutrum neque accumsan hendrerit montes consequat. Afringilla scelerisque senectus dis orci natoque phasellus. Fames pharetra nascetur dis imperdiet mollis fringilla. Donec faucibus vel adipiscing nullam gravida integer parturient:\n\nLitora ipsum lobortis tincidunt bibendum eget sed lacinia porta. Velit mollis vivamus sagittis quam mattis tempor diam, nulla nascetur. Luctus litora senectus senectus mus sem; vitae porttitor. Quis\nparturient nam finibus id. Quisque porta dictum metus; felis habitant pellentesque.\nVehicula consectetur gravida quam nulla dictum pretium natoque.\n\nHere’s a mermaid flow chart:\n\n\n\n\n\nflowchart LR\n  A[Get Up] --&gt; B(Brush Teeth)\n  B --&gt; C{Decision}\n  C --&gt; D[Make Breakfast]\n  C --&gt; E[Make Bed]\n\n\n\n\n\n\n\n\nTaciti tristique nibh primis pharetra pulvinar. Aliquet odio faucibus litora magna morbi mi lectus bibendum. Magna integer malesuada massa, commodo facilisis vulputate?\n\n\n\n\n\n\nLibero curae nisl nisl diam nisi consequat. Fames aliquam habitant potenti convallis vulputate phasellus elementum? Porta parturient sociosqu; nullam sit hac placerat porta arcu vehicula. Gravida nisi ultrices sed massa fringilla magnis efficitur aenean.\n\n\nLibero curae nisl nisl diam nisi consequat. Fames aliquam habitant potenti convallis vulputate phasellus elementum? Porta parturient sociosqu; nullam sit hac placerat porta arcu vehicula. Gravida nisi ultrices sed massa fringilla magnis efficitur aenean.\n\n\n\nThis is from my Undergraduate thesis:\n\n“If we let \\(\\theta_c^{(s)}\\) be the MCMC sample from iteration s of chain c for parameter \\(\\theta\\), and \\(\\theta_c^{(s-\\ell)}\\) be the MCMC sample from iteration \\(s-\\ell\\) of chain c for parameter \\(\\theta\\), then we can achieve our effective sample size and autocorrelation from our total number of iterations S by Equation:”\n\n\\[\n    Ess_c = \\frac{N}{1 + 2\\sum_{\\ell-1}^N\\rho_c(\\ell)} \\newline\n\\] \\[\n\\rho_c(\\ell) = Cor(\\theta_c^{(s)},\\theta_c^{(s-\\ell)})\n\\]\nwhere \\(\\ell\\) is the lag of our sample\nTo estimate the significance and uncertainty of my Köppen-Geiger Climate Classification coefficients, I calculated 95% Highest Posterior Density (HPD) Intervals for all model parameters, as seen in the table below. These HPD intervals are the credible intervals (\\(\\ell\\), u) such that the width \\(u - \\ell\\) is minimized while keeping the desired coverage probability such that P(\\(\\ell\\) &lt; \\(\\theta\\) &lt; u) = .95, but the width of the interval is as small as possible.\n\n\n\n\nTerm\nLower_Bound\nHigher_Bound\n\n\n\n\n1\n(Intercept)\n13.69\n13.86\n\n\n2\nXC2\n0.87\n0.87\n\n\n3\nCRegionBSk\n-2.08\n-1.91\n\n\n4\nCRegionBWh\n0.16\n0.37\n\n\n5\nCRegionBWk\n-0.32\n-0.12\n\n\n6\nCRegionCfa\n-1.90\n-1.73\n\n\n7\nCRegionCfb\n-1.62\n-1.38\n\n\n8\nCRegionCsa\n-1.48\n-1.28\n\n\n9\nCRegionCsb\n-1.87\n-1.70\n\n\n10\nCRegionDfa\n-3.70\n-3.52\n\n\n11\nCRegionDfb\n-2.60\n-2.42\n\n\n12\nCRegionDfc\n-1.74\n-1.54\n\n\n13\nCRegionDsb\n-1.56\n-1.34\n\n\n14\nCRegionDsc\n-0.85\n-0.57\n\n\n15\nCRegionDwa\n-3.50\n-3.15\n\n\n16\nCRegionDwb\n-3.41\n-2.94\n\n\n17\nsigma\n2.99\n3.01\n\n\n18\nmean_PPD\n11.85\n11.87\n\n\n\nHere are some images\n\n\n\nOne picture of Odin, my older sister’s dog\n\n\n\n\n\nThis dog is basically mine, I raised this chonky boy\n\n\nHere’s a video from my presentation in Germany"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "simple_quarto_website",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSociosqu facilisi interdum pulvinar facilisi ligula aenean nam habitant.↩︎"
  }
]